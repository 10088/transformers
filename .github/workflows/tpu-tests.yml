name: TPU tests

on:
  push:
    branches:
      - tpu*

env:
  TRANSFORMERS_IS_CI: yes
  RUN_SLOW: yes
  XRT_TPU_CONFIG: localservice;0;localhost:51011

jobs:
  run_tpu_tests:
    runs-on: [self-hosted, tpu]
    steps:
      - name: Launcher docker
        uses: actions/checkout@v2

      - name: Tests
        run: |
          whoami
          python -c "import torch; import torch_xla.core.xla_model as xm; print(xm.xla_device())"
